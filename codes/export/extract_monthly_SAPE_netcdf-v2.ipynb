{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "# sys.path.append(\"codes/modules\") # add custom Vibe 's modules\n",
    "# sys.path.append('../..') # add standard 's modules\n",
    "# sys.path.append('~/pyfesom/codes/modules')\n",
    "# sys.path.append('~/pyfesom/modules')\n",
    "sys.path.append('../..') # add standard 's modules\n",
    "sys.path.append('../modules')\n",
    "\n",
    "import pyfesom as pf\n",
    "from load_mesh_data_new import load_mesh\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('/home/hbkoziel/pyfesom/pyfesom/python-gsw/')\n",
    "import gsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Running this file loads tracers from old FESOM-REcoM2 output file (oce.mean.nc)\n",
    "# and saves each tracer in an individual file\n",
    "# \n",
    "#  Input:\n",
    "#  - mesh_id: Name of mesh, will be added to the netcdf name\n",
    "#  - meshpath: Speciefies where the target mesh is stored\n",
    "#  - save_netcdf: If true, netcdf will be created\n",
    "#  - delete_old_netcdf: If a netcdf file with the same name exists, a new cannot \n",
    "#    be made. If set to true, an old netcdf with the same name will be deleted\n",
    "#\n",
    "#  Output:\n",
    "#  - netcdf file for each tracer in the old file\n",
    "#  \n",
    "#  During running, keep an eye on the output in the terminal, to see if it \n",
    "#  makes sense. \n",
    "#\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Turner_Rsubrho(SA, CT, p):\n",
    "    SA, CT, p = np.broadcast_arrays(SA, CT, p, subok=True)\n",
    "    p_mid = 0.5 * (p[0:-1, ...] + p[1:, ...])\n",
    "    SA_mid = 0.5 * (SA[0:-1, ...] + SA[1:, ...])\n",
    "    CT_mid = 0.5 * (CT[0:-1, ...] + CT[1:, ...])\n",
    "\n",
    "    dSA = SA[0:-1, ...] - SA[1:, ...]\n",
    "    dCT = CT[0:-1, ...] - CT[1:, ...]\n",
    "    [rho, alpha, beta] = gsw.rho_alpha_beta(SA_mid, CT_mid, p_mid)\n",
    "    #Tu = np.arctan2((alpha * dCT + beta * dSA), (alpha * dCT - beta * dSA))\n",
    "    #Tu = Tu * (180 / np.pi)\n",
    "\n",
    "    Rsubrho = np.zeros_like(dSA) + np.NaN\n",
    "    Inz = dSA != 0\n",
    "    Rsubrho[Inz] = (alpha[Inz] * dCT[Inz]) / (beta[Inz] * dSA[Inz])\n",
    "    return Rsubrho, rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The *usepickle = True* and the pickle file (*pickle_mesh*) exists.\n",
      " We load the mesh from it.\n"
     ]
    }
   ],
   "source": [
    "# Loading mesh for run\n",
    "\n",
    "mesh_id    = 'meshArc4.5'\n",
    "meshpath   = '/scratch/usr/hbkoziel/mesh/'+mesh_id+'/'            # Defining path where mesh is stored\n",
    "#mesh = pf.load_mesh(meshpath, usepickle=False, get3d=True, usejoblib = False)                                    # Loading mesh, stores it in mesh.****  \n",
    "#mesh = pf.fesom_mesh(meshpath, get3d=True)\n",
    "#mesh.zlevs = -mesh.zlevs                                            # Depth is made negative\n",
    "mesh = load_mesh(meshpath, get3d=True)\n",
    "\n",
    "tracername = 'SAPE'\n",
    "first_year = 1998\n",
    "last_year  = 1999\n",
    "years      = np.arange(first_year,last_year+1,1)\n",
    "runid\t= 'Arc12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -0.,   -0.,   -0., ..., 5900., 5900., 5900.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh.z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure = gsw.p_from_z(-mesh.z3, mesh.y3, geo_strf_dyn_height=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Settings for netcdf file\n",
    "\n",
    "save_netcdf       = True                                            # Saves the interpolated field in netcdf file\n",
    "delete_old_netcdf = True                                            # If a netcdf file with the same name exists it will be deleted\n",
    "input_directory  = '/scratch/usr/hbkoziel/'+runid+'/netcdf/'       # Where the netcdf is saved\n",
    "output_directory  = '/scratch/usr/hbkoziel/'+runid+'/netcdf/'\n",
    "plot_netcdf       = True                                           # Reads DIN from the created netcdf file, else it plots the interpolated field (should be the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading index...\n",
      "LOADING DONE\n",
      "SORTING...\n",
      "CLEANING DONE...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (173576,) (753179,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ea91de2ef102>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mind_bio3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mind1\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mind2\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mind3\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mind4\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mind5\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0mind6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_bio3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mind_bio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind_bio1\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0mind_bio2\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0mind_bio3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/sw/tools/anaconda2/2019.10/skl/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1848\u001b[0m         filler = (fill_int if is_self_int_dtype and is_other_int_dtype\n\u001b[1;32m   1849\u001b[0m                   else fill_bool)\n\u001b[0;32m-> 1850\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0movalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m         unfilled = self._constructor(res_values,\n\u001b[1;32m   1852\u001b[0m                                      index=self.index, name=res_name)\n",
      "\u001b[0;32m/sw/tools/anaconda2/2019.10/skl/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1787\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (173576,) (753179,) "
     ]
    }
   ],
   "source": [
    "print('loading index...')\n",
    "df = pd.read_csv(meshpath+'/bioregion_index_latlon.csv', delimiter=',',header=0)\n",
    "print('LOADING DONE')\n",
    "df.sort_values(by ='Unique_ID',inplace=True)\n",
    "index = df[\"Unique_ID\"]\n",
    "index_unique = df.Unique_ID.unique().tolist()\n",
    "index_unique.pop(-1)\n",
    "print('SORTING...')\n",
    "names = df.Name.unique().tolist()\n",
    "names.pop(-1)\n",
    "names[3]='Beaufort Sea - shelf'\n",
    "names[4]='Amundsen-Viscount'\n",
    "names.append('All Arctic Ocean (>66N)')\n",
    "print('CLEANING DONE...')\n",
    "\n",
    "ind_bio1 = df.full_index[df.Unique_ID == 24]\n",
    "ind_bio2 = df.full_index[df.Unique_ID == 25]\n",
    "ind1 = (np.array(mesh.topo > 300) & np.array(mesh.topo < 800))\n",
    "ind2 = ~(np.array(mesh.y2 < 75) & np.array(np.abs(mesh.x2) < 80))\n",
    "ind3 = ~(np.array(mesh.y2 < 66) & np.array(np.abs(mesh.x2) >= 80))\n",
    "ind4 = ~(np.array(mesh.y2 < 80) & np.array(mesh.x2 < -20) & np.array(mesh.x2 > -100))\n",
    "ind5 = ~(np.array(mesh.y2 < 80) & np.array(mesh.x2 > -20) & np.array(mesh.x2 < 0))\n",
    "ind6 = ~(np.array(mesh.y2 < 80) & np.array(mesh.x2 > 20) & np.array(mesh.x2 < 60))\n",
    "\n",
    "ind_bio3=ind1&ind2&ind3&ind4&ind5&ind6\n",
    "x = np.where(ind_bio3)[0]\n",
    "ind_bio = np.intersect1d(ind_bio1|ind_bio2|ind_bio3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753179,)\n",
      "(105767,)\n",
      "(753179,)\n"
     ]
    }
   ],
   "source": [
    "print ind_bio3.shape\n",
    "print ind_bio2.shape\n",
    "print mesh.x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/tools/anaconda2/2019.10/skl/lib/python2.7/site-packages/ipykernel_launcher.py:46: UserWarning: Warning: converting a masked element to nan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The netcdf file SAPE.1998.monthly_v2.nc has been deleted to make room for your file of the same name.\n",
      "New netcdf file ( SAPE.1998.monthly_v2.nc ) has been created.\n",
      "Location: /scratch/usr/hbkoziel/Arc12/netcdf/\n",
      "1999\n",
      "The netcdf file SAPE.1999.monthly_v2.nc has been deleted to make room for your file of the same name.\n",
      "New netcdf file ( SAPE.1999.monthly_v2.nc ) has been created.\n",
      "Location: /scratch/usr/hbkoziel/Arc12/netcdf/\n"
     ]
    }
   ],
   "source": [
    "for ind in range(0,len(years)):\n",
    "    netcdf_name       = tracername+'.'+str(years[ind])+'.monthly_v2.nc'\n",
    "    print years[ind]\n",
    "    # ==============================================================================\n",
    "    # Loading data\n",
    "\n",
    "    ncfile1\t= input_directory+'temp.'+str(years[ind])+'.monthly.nc'\n",
    "    f1\t= Dataset(ncfile1,'r')\n",
    "    t\t= f1.variables['temp'][8,:]\n",
    "    f1.close()\n",
    "    \n",
    "    ncfile2\t= input_directory+'salt.'+str(years[ind])+'.monthly.nc'\n",
    "    f2\t= Dataset(ncfile2,'r')\n",
    "    s\t= f2.variables['salt'][8,:]\n",
    "    f2.close()\n",
    "    \n",
    "    ncfile3\t= input_directory+'mixlay.'+str(years[ind])+'.monthly.nc'\n",
    "    f3\t= Dataset(ncfile3,'r')\n",
    "    mld\t= f3.variables['mixlay'][8,:]\n",
    "    f3.close()\n",
    "    \n",
    "    HLD = np.zeros(len(mesh.x2))\n",
    "    HLT = np.zeros(len(mesh.x2))\n",
    "    APE = np.zeros(len(mesh.x2))\n",
    "    for i in range(0,len(mesh.x2)):\n",
    "        if ((mesh.y2[i] >= 70) & (mesh.topo[i]>300)):\n",
    "            #print 'derive HL'\n",
    "            #ind = (np.abs(mesh.topo[i]-mesh.zlevs)).argmin(axis=0)\n",
    "            ind_depth = np.array(mesh.n32[i,0:20]) # depth max 580m\n",
    "            ind_depth = np.reshape(ind_depth, ind_depth.size)\n",
    "                \n",
    "            z = pressure[ind_depth]\n",
    "            dz2 = z[:-1]**2 - z[1:]**2\n",
    "            \n",
    "            tt = t[ind_depth]\n",
    "            tt = np.reshape(tt, tt.size)\n",
    "            ss = s[ind_depth]\n",
    "            ss = np.reshape(ss, ss.size)\n",
    "            [Ro1,ro] = Turner_Rsubrho(ss,tt,z)\n",
    "            hl_ind = (np.abs(0.1-Ro1)).argmin(axis=0)\n",
    "            HLD[i] = mesh.z3[ind_depth[hl_ind]]\n",
    "            if HLD[i] > mld[i]:\n",
    "                HLT[i] = HLD[i] - mld[i]\n",
    "            else:\n",
    "                HLT[i] = 0\n",
    "            APE[i] = np.sum(0.5 * 9.81 * (ro[:hl_ind]-ro[hl_ind]) * dz2[:hl_ind])\n",
    "        \n",
    "        #tracer = [HL1,HL2,HL3,HL4,HL5,HL6,HL7,HL8,HL9,HL10,HL11,HL12]\n",
    "            \n",
    "    tracershape = np.shape(HLD)\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # Testing if a netcdf file with the same name exists, if yes, it must be removed\n",
    "    # to save a new one.\n",
    "\n",
    "    if os.path.isfile(output_directory+netcdf_name) and delete_old_netcdf:\n",
    "      os.remove(output_directory+netcdf_name)\n",
    "      print \"The netcdf file \"+netcdf_name+\" has been deleted to make room for your file of the same name.\"\n",
    "    elif os.path.isfile(netcdf_name):\n",
    "      statement = \"The netcdf file \"+netcdf_name+\" already exists! It must be removed for a new one to be created. This can be done by changing your settings.\"\n",
    "      sys.exit(statement)\n",
    "\n",
    "    if not os.path.isdir(output_directory):\n",
    "      os.makedirs(output_directory)\n",
    "      print 'Directory '+output_directory+' has been created'\n",
    "\n",
    "    # ==============================================================================\n",
    "    # Creating netcdf file\n",
    "    if save_netcdf:  \n",
    "      import time\n",
    "      w_nc_fid = Dataset(output_directory+netcdf_name, 'w', format='NETCDF4_CLASSIC')      # Create and open new netcdf file to write to\n",
    "      w_nc_fid.description = 'Mean Summer (Sept) Halocline indicators'\n",
    "      w_nc_fid.history     = 'Created ' + time.ctime(time.time())\n",
    "\n",
    "      nod2d    = w_nc_fid.createDimension('nod2d', mesh.n2d)               # Create dimension: number of 3d nodes\n",
    "\n",
    "      w_nc_var = w_nc_fid.createVariable('HLD', 'f8',('nod2d'))           # 'DIN' is name of saved variable                                                                    # 'f8' sets presicion to 64-bit floating point\n",
    "      w_nc_var.setncatts({'long_name': u'Mean Summer Halocline Depth',\\\n",
    "                          'units': u'm'})\n",
    "      w_nc_fid.variables['HLD'][:] = HLD  \n",
    "    \n",
    "      w_nc_var = w_nc_fid.createVariable('HLT', 'f8',('nod2d'))           # 'DIN' is name of saved variable                                                                    # 'f8' sets presicion to 64-bit floating point\n",
    "      w_nc_var.setncatts({'long_name': u'Mean Summer Halocline Thickness',\\\n",
    "                          'units': u'm'})\n",
    "      w_nc_fid.variables['HLT'][:] = HLT\n",
    "        \n",
    "      w_nc_var = w_nc_fid.createVariable('APE', 'f8',('nod2d'))           # 'DIN' is name of saved variable                                                                    # 'f8' sets presicion to 64-bit floating point\n",
    "      w_nc_var.setncatts({'long_name': u'Mean Summer Available Potential Energy',\\\n",
    "                          'units': u'J/m2'})\n",
    "      w_nc_fid.variables['APE'][:] = APE \n",
    "    \n",
    "    \n",
    "      w_nc_fid.close()                                                     # close the new file                \n",
    "\n",
    "      cwd = os.getcwd()\n",
    "      print \"New netcdf file (\",netcdf_name,\") has been created.\"\n",
    "      print \"Location: \"+output_directory\n",
    "    else:\n",
    "      print 'You have specified not to save your field in netcdf file'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
